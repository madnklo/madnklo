##########################################################################################
#
# Copyright (c) 2009 The MadGraph5_aMC@NLO Development team and Contributors
#
# This file is a part of the MadGraph5_aMC@NLO project, an application which 
# automatically generates Feynman diagrams and matrix elements for arbitrary
# high-energy processes in the Standard Model and beyond.
#
# It is subject to the MadGraph5_aMC@NLO license which should accompany this 
# distribution.
#
# For more information, visit madgraph.phys.ucl.ac.be and amcatnlo.web.cern.ch
#
##########################################################################################
"""Common functions for QCD local currents."""

import os
import math
from bidict import bidict
from pprint import pformat

import madgraph.integrator.mappings as mappings
import madgraph.integrator.vectors as vectors
import madgraph.various.misc as misc
from madgraph.core.subtraction import Current, BeamCurrent, IntegratedBeamCurrent, \
    IntegratedCurrent, Counterterm, SubtractionLeg
from madgraph.core.base_objects import EpsilonExpansion

import commons.utils as utils

pjoin = os.path.join

CurrentImplementationError = utils.CurrentImplementationError
import madgraph.core.subtraction as sub

#=========================================================================================
#
# General current implementation
#
# This is the most general implementation of a subtraction current in MadNkLO and should
# be able to accommodate any current (at least within colorful where each colour dipole
# does *not* yield different reduced kinematics).
#
#=========================================================================================

class CompoundVariables(object):

    def __init__(self, *variables_generators):
        self.variables_generators = variables_generators

    def __call__(self, higher_PS_point, lower_PS_point, bundles_info, **opts):
        """ Calls in sequence the variables for each bundles, and return the aggregated list."""

        assert(len(bundles_info)==len(self.variables_generators))

        all_variables = []
        for bundle_info, variables_generator in zip(bundles_info,self.variables_generators):
            if variables_generator is not None:
                all_variables.append(variables_generator(
                    higher_PS_point,
                    lower_PS_point[bundle_info['parent']] if bundle_info['parent'] is not None else None,
                    tuple(list(bundle_info['initial_state_children'])+list(bundle_info['final_state_children'])),
                    **opts)[0]
                )
            else:
                all_variables.append({})
        return all_variables

class GeneralCurrent(utils.VirtualCurrentImplementation):
    """Common functions for QCD local collinear currents."""

    # Overwrite this value in daughter classes to enable their debugging (especially of the function does_implement_this_current())
    DEBUG = False

    # Specify the class that will store the evaluation result from this current. Typically either:
    # utils.SubtractionCurrentEvaluation or util.BeamFactorizationCurrentEvaluation
    subtraction_current_evaluation_class = utils.SubtractionCurrentEvaluation

    # These initialisation variables will be generated by the function `does_implement_this_current`.
    # These are dictionaries that contain the following entries:
    # {
    #   'leg_numbers_map'   : { leg_number_in_matching_ss -> leg_number_in_higher_PS_point },
    #   'beam_type'         :  None if not relevant else the name of the beam type specified in the corresponding current
    #   'beam_PDGs'         :  None if not relevant else the list of PDGs involved in the beam specified in the current
    #   'distribution_type' :  None if not a distribution else value in ['bulk', 'counterterm', 'endpoint']
    #   'active_fermions'   :  None if not relevant for this current, otherwise the list of PDGs of the active fermions
    #   'NF'                :  None if not relevant for this current, otherwise the number of active massless fermions
    #   'has_initial_state' : # Simple flag indicating if that particular current involve initial states
    # }
    expected_init_opts = ('currents_properties',)

    # This should be defined by daughter class, this defining current will be matched against the one that this
    # singular structure potentially matches. Notice that a list of defining main currents must be specified. that list can
    # contain a single current or many, but they can only differ by the flavors involved in their matching singular structure.
    # main_current = []

    # One can potentially add here non factorisable currents that are part of the definition of what this class implement.
    # Example: ( (C(4,5),),
    #            (F(1),),
    #            (F(2),)
    #          )
    # The combination of C(4,5) (involving a symmetric recoil against the initial states) and F(1) and F(2) (PDF
    # counterterms) are not factorisable and must therefore be treated at once. In that case, C(4,5) is the
    # "defining" current while F(1) and F(2) will be stored again as non factorisable currents.
    # This must be left as an empty set when there is no such non-factorisable currents.
    # Here again each element is a list of (possibly only one) current instances if one wants to include multiple flavour combinations.
    # non_factorisable_currents = []
    defining_currents = [] # main_current + non_factorisable_currents

    # The class attribute mapping rules specifies each level of mapping in an ordered list, each
    # composed of a dictionary with the necessary component for performing this mapping:
    mapping_rules = NotImplemented

    # Decide whether one must divide by the jacobian or not. By default we don't
    divide_by_jacobian = False

    # By default, the currents do no support helicity assignment
    supports_helicity_assignment = False

    # The attirbutes below are not used in this implementation
    get_recoilers   = None
    factor          = None
    mapping         = None
    is_cut          = None

    # A global variables builder can also be supplied and will be called to build the overall variables
    # that need to know about the entire mapping history. It can be left to None if not necessary.
    variables = None

    # Note that for integrated counterterms that do no require mappings, the mapping_rules class variable
    # can remain empty
    mapping_rules = []

    # Example: for the nested collinear FF within IF
    # mapping_rules = [
    #     {
    #         'singular_structure'    : sub.SingularStructure(substructures=(sub.CollStructure(
    #             substructures=tuple([]),
    #             legs=(
    #                 sub.SubtractionLeg(10, +2, sub.SubtractionLeg.FINAL),
    #                 sub.SubtractionLeg(11, -2, sub.SubtractionLeg.FINAL),
    #             )
    #         ),)),
    #         'mapping'               : colorful_pp_config.final_coll_mapping,
    #         # Intermediate legs should be strictly superior to a 1000
    #         'momenta_dict'          : bidict({1001:frozenset((10,11))}),
    #         'variables'             : currents.CompoundVariables(kernel_variables.colorful_pp_FFn_variables),
    #         'is_cut'                : colorful_pp_config.generalised_cuts,
    #         'reduced_recoilers'     : colorful_pp_config.get_initial_state_recoilers,
    #         'additional_recoilers'  : sub.SubtractionLegSet([sub.SubtractionLeg(1, +1, sub.SubtractionLeg.INITIAL)]),
    #     },
    #     {
    #         'singular_structure': sub.SingularStructure(substructures=(sub.CollStructure(
    #             substructures=tuple([]),
    #             legs=(
    #                 sub.SubtractionLeg(1, +1, sub.SubtractionLeg.INITIAL),
    #                 sub.SubtractionLeg(1001, +1, sub.SubtractionLeg.FINAL),
    #             )
    #         ),)),
    #         'mapping'               : colorful_pp_config.initial_coll_mapping,
    #         # -1 indicates that this ID should be replaced by the first overall parent connecting to the ME
    #         'momenta_dict'          : bidict({-1: frozenset((1001, 1))}),
    #         'variables'             : currents.CompoundVariables(kernel_variables.colorful_pp_IFn_variables),
    #         'is_cut'                : colorful_pp_config.generalised_cuts,
    #         'reduced_recoilers'     : colorful_pp_config.get_final_state_recoilers,
    #         'additional_recoilers'  : sub.SubtractionLegSet([]),
    #     },
    # ]

    def __init__(self, model, **opts):

        super(GeneralCurrent, self).__init__(model, **opts)

        # Extract constants from the UFO model if present, otherwise take default values
        try:
            model_param_dict = self.model.get('parameter_dict')
        except:
            model_param_dict = dict()

        self.TR = model_param_dict.get('TR', utils.Constants.TR)
        self.NC = model_param_dict.get('NC', utils.Constants.NC)
        self.CF = model_param_dict.get('CF', (self.NC ** 2 - 1) / (2 * self.NC))
        self.CA = model_param_dict.get('CA', self.NC)

        self.EulerGamma = utils.Constants.EulerGamma
        # S_\eps = (4 \[Pi])^\[Epsilon] E^(-\[Epsilon] EulerGamma)
        # self.SEpsilon   = utils.Constants.SEpsilon
        # The SEpsilon volume factor is factorized from all virtual and integrated contributions
        # so that the poles between the two cancel even before multiplying by SEpsilon, hence
        # making the result equivalent to what one would have obtained by multiplying by SEpsilon=1.
        self.SEpsilon = EpsilonExpansion({0: 1.})

        for opt_name in self.expected_init_opts:
            try:
                setattr(self, opt_name, opts.pop(opt_name))
            except KeyError:
                raise CurrentImplementationError(
                    "__init__ of " + self.__class__.__name__ + " requires " + opt_name)

    @classmethod
    def check_current_properties(cls, current):
        try:
            return all([
                current['squared_orders'] == cls.squared_orders,
                current['n_loops'] == cls.n_loops,
                current['resolve_mother_spin_and_color'] == cls.resolve_mother_spin_and_color,
                isinstance(current, cls.current_type_implemented)
            ])
        except KeyError as ke:
            raise CurrentImplementationError(
                "The current " + cls.__name__ + " called check_current_properties " +
                "without setting " + str(ke) + ", please review your implementation")

    @classmethod
    def check_non_factorisable_currents(cls, current):
        try:
            return all([
                current['squared_orders'] == cls.squared_orders,
                current['n_loops'] == cls.n_loops,
                current['resolve_mother_spin_and_color'] == cls.resolve_mother_spin_and_color,
                not isinstance(current, cls.non_local_currents)
            ])
        except KeyError as ke:
            raise CurrentImplementationError(
                "The current " + cls.__name__ + " called check_current_properties " +
                "without setting " + str(ke) + ", please review your implementation")

    @classmethod
    def build_equivalency_sets(cls, model):
        """ By default, the equivalency class is such that light quarks and antiquarks will be
        matched indiscriminatory. In the case of electroweak theory you may
        not want to put the quarks and antiquarks in the same equivalency class. For QCD
        you do."""

        return [set(range(1, model.get_nflav()+1)) | set(range(-model.get_nflav(), 0))]

    @classmethod
    def match_singular_structure(cls, singular_structure, template_singular_structure, model):
        """ This function tests whether the singular structure passed in argument can match the template one.
        It returns the corresponding leg_numbers_map if so and None otherwise.
        Also make sure to unpack the singular structures first before matching them, so as to make sure that the
        top-level substructures directly embeds them, e.g. ((C(3,4),C(5,6),),) -> (C(3,4),C(5,6),) """

        return template_singular_structure.unpack().map_leg_numbers(
                                            singular_structure.unpack(), cls.build_equivalency_sets(model))

    @classmethod
    def match_current(cls, current, template_current, model, debug=False):
        """ This function tests whether the template current specified matches the one to test.
        Note that the template_current can either be a single current or a list of current whose singular structure
        only differ by flavour configurations.
        If so it returns a list of current properties in the form of a dictionary, otherwise it returns None."""

        # Make sure to cast the template_current into a list of currents if it is given as just one current.
        if not isinstance(template_current, (list, tuple)):
            all_template_currents = [template_current, ]
        else:
            all_template_currents = template_current

        current_type = current.get_type()  # Can be either 'Current', 'IntegratedCurrent', 'BeamCurrent' or 'IntegratedBeamCurrent'

        for a_template_current in all_template_currents:

            matching_current_properties = {
                'leg_numbers_map': None,  # { leg_number_in_matching_ss -> leg_number_in_higher_PS_point },
                'beam_type': None, # if not relevant else the name of the beam type specified in the corresponding current
                'beam_PDGs': None, # if not relevant else the list of PDGs involved in the beam specified in the current
                'distribution_type': None,  # if not a distribution else value in ['bulk', 'counterterm', 'endpoint']
                'active_fermions': None, # if not relevant for this current, otherwise the list of PDGs of the active fermions
                'NF': None,  # if not relevant for this current, otherwise the number of active massless fermions
                'has_initial_state' : False # Simple flag indicating if that particular current involve initial states
            }

            if current_type != a_template_current.get_type():
                if debug: misc.sprint("Current type mismatch: template=%s vs target=%s"%(a_template_current.get_type(),current_type))
                continue

            # Match basic characteristics that all currents must match
            found_a_mismatch = False
            for basic_property in ['squared_orders', 'n_loops', 'resolve_mother_spin_and_color']:
                if a_template_current[basic_property] not in [None, current[basic_property]]:
                    if debug: misc.sprint("%s mismatch: template=%s vs target=%s" % (
                                        basic_property, a_template_current[basic_property], current[basic_property]))
                    found_a_mismatch = True
                    break
                else:
                    matching_current_properties[basic_property] = current[basic_property]
            if found_a_mismatch:
                continue

            # Match additional characteristics if the current involve beam convolutions
            if current_type in ['BeamCurrent', 'IntegratedBeamCurrent']:

                if current_type in ['IntegratedBeamCurrent', ]:
                    matching_current_properties['distribution_type'] = 'endpoint'

                if current_type in ['BeamCurrent']:
                    found_a_mismatch = False
                    for beam_property in ['distribution_type', ]:
                        # Note that when setting None for this property in the template current, this implies that
                        # it should match all variants.
                        if a_template_current[beam_property] is not None and \
                                                    current[beam_property] not in a_template_current[beam_property]:
                            if debug: misc.sprint("%s mismatch: template=%s vs target=%s" % (
                                beam_property, a_template_current[beam_property], current[beam_property]))
                            found_a_mismatch = True
                            break
                        else:
                            matching_current_properties[beam_property] = current[beam_property]
                    if found_a_mismatch:
                        continue

                found_a_mismatch = False
                for beam_property in ['beam_type', 'beam_PDGs']:
                    # Note that when setting None for this property in the template current, this implies that
                    # it should match all variants.
                    if a_template_current[beam_property] is not None and \
                        current[beam_property] != a_template_current[beam_property] and \
                        ( (not isinstance(a_template_current[beam_property], (list, tuple))) or
                          (current[beam_property] not in a_template_current[beam_property])):
                        if debug: misc.sprint("%s mismatch: template=%s vs target=%s" % (
                            beam_property, a_template_current[beam_property], current[beam_property]))
                        found_a_mismatch = True
                        break
                    else:
                        matching_current_properties[beam_property] = current[beam_property]
                if found_a_mismatch:
                    continue

                # Now also add useful derived quantities
                # Retrieve NF from the active beam_PDGs, omitting all massless gauge vectors
                # and grouping particles and anti particles
                # CT can involve beam convolutions even though they do not relate to beam factorisation, in which case
                # they will not specify any beam_PDGs. This is for example the case for the soft and final-final CT
                # when they recoil symmetrically against the initial state. In that case, we set the "active_fermions" to
                # None since this information should not be necessary anyway for these kernels.
                # Same for NF.
                if current['beam_PDGs']:
                    matching_current_properties['active_fermions'] = tuple(
                                            sorted(list(set(pdg for pdg in current['beam_PDGs'] if
                                                                            model.get_particle(pdg).get('spin') == 2))))
                if matching_current_properties['active_fermions']:
                    abs_active_fermions = tuple(set(abs(pdg) for pdg in matching_current_properties['active_fermions']))
                    matching_current_properties['NF'] = len([1 for pdg in abs_active_fermions if
                                                            model.get_particle(pdg).get('mass').upper() == 'ZERO'])

            # Now attempt to match singular structures
            leg_numbers_map = cls.match_singular_structure(
                                    current['singular_structure'], a_template_current['singular_structure'], model)
            if leg_numbers_map is None:
                if debug: misc.sprint("Singular structure mismatch: template=%s vs target=%s" % (
                                        a_template_current['singular_structure'], current['singular_structure']))
                continue
            else:
                matching_current_properties['leg_numbers_map'] = leg_numbers_map

            # Add a simple flag indicating wheter this matched current has initial states
            matching_current_properties['has_initial_state'] = current.get('singular_structure').get_all_legs().has_initial_state_leg()

            # This completes the matching procedure and when reaching this point we can return the matching information
            return matching_current_properties

        # Reaching this instruction implies that no matching current was found
        return None

    @classmethod
    def currents_block_to_debug(cls, currents_block):
        """ Helper debug function that should return True for a currents_block that warrants debug printout. """

        # By default, do not debug any currents block
        return False

        # The expression below is an example of how to select the particular NLO FF currents block
        return len(currents_block)==1 and \
            len(currents_block[0]['singular_structure'].substructures)==1 and \
            currents_block[0]['singular_structure'].substructures[0].name()=='C' and \
            len(currents_block[0]['singular_structure'].substructures[0].legs)==2 and \
            all(l.state == l.FINAL for l in currents_block[0]['singular_structure'].substructures[0].legs) and \
            all(abs(l.pdg) in range(1,7) for l in currents_block[0]['singular_structure'].substructures[0].legs)

    @classmethod
    def does_implement_these_currents(cls, currents_block, model):
        """ Tests whether this class can implement the specified current, possibly together with additional
         non factorisable currents present in the counterterm.nodes."""

        init_dict = {'currents_properties' : [] }

        # First and foremost check whether the number of non-factorisable currents in the tested counterterm
        # matches the number of non-factorisable currents that this class considers
        if len(currents_block) != len(cls.defining_currents):
            return None

        debug_currents_matching_procedure = cls.DEBUG and cls.currents_block_to_debug(currents_block)

        # Now attempt to separately match each template current
        already_matched_current_indices = []
        for defining_current in cls.defining_currents:
            for i_matched_current, current in enumerate(currents_block):
                if i_matched_current in already_matched_current_indices:
                    continue
                matched_current_properties = cls.match_current(current, defining_current, model,
                                                                                debug=debug_currents_matching_procedure)
                if matched_current_properties is None:
                    continue
                else:
                    init_dict['currents_properties'].append(matched_current_properties)
                    already_matched_current_indices.append(i_matched_current)
                    # We found a match for this defining current, proceed to the next one
                    break
            else:
                # We found no match for this defining current, this class can therefore not support these currents
                if debug_currents_matching_procedure: misc.sprint( "Did not match currents block %s to class %s" % (
                    currents_block, cls.__name__ ) )
                return None

        if debug_currents_matching_procedure: misc.sprint(
            "Successful matching of currents block %s to class %s, with the following initialisation dict:\n%s" % (
                currents_block, cls.__name__, pformat(init_dict) ))

        return init_dict

    # Dummy soft-kernel, it can be specialised by the daughter class if it should not be dummy
    def kernel(self, evaluation, steps_and_bundles_variables, global_variables):
        """Evaluate a collinear type of splitting kernel, which does *not* need to know about the reduced process
        Should be specialised by the daughter class if not dummy
        """

        return evaluation

    def call_soft_kernel(self, evaluation, reduced_process, *args):
        """Evaluate a collinear type of splitting kernel, which *does* need to know about the reduced process
        Should be specialised by the daughter class if more info than just the colored partons must be extracted
        by from the reduced process.
        """

        colored_parton_numbers = {}
        for leg in reduced_process.get('legs'):
            leg_color_quantum_number = self.model.get_particle(leg.get('id')).get('color')
            if leg_color_quantum_number==1:
                continue
            colored_parton_numbers[leg.get('number')] = (leg_color_quantum_number, leg.get('state'))

        return self.soft_kernel(evaluation,colored_parton_numbers,*args)

    def soft_kernel(self, evaluation, colored_partons, all_steps_info, global_variables):
        """Evaluate a soft type of splitting kernel, which *does* need to know about the reduced process
        Should be specialised by the daughter class if not dummy
        """

        return evaluation

    def map_leg_number(self, leg_numbers_map, leg_number, parents):
        """
        Map a leg number to its true ID in a specific process.
        Inputs:
            - leg_number: ID of the leg within the singular structure
            - parents: list of process-specific parent momentum in the top-level reduced process. They
        Rules are as follows:
            leg_number < 0 : Should be replaced by the overall parent #abs(leg_number) of the substructure considered.
            leg_number >= 0 : Should be replaced according to self.leg_numbers_map
            leg_number > 1000: Should be left as is given that this is an intermediate leg number
        """
        if leg_number > 1000:
            return leg_number
        elif leg_number < 0:
            return parents[abs(leg_number)-1]
        else:
            return leg_numbers_map[leg_number]

    def map_leg_numbers_in_singular_structure(self, leg_numbers_map, singular_structure, parents):
        """ Recursively walk through the singular structure and map the generic subtraction leg numbers to either:
        - the explicit indices of the resovled process
        - the explicit indices of the unresolved process
        - dummy intermediate indices
        """

        new_subtraction_legs = []
        for leg in singular_structure.legs:
            new_subtraction_legs.append(sub.SubtractionLeg(self.map_leg_number(leg_numbers_map, leg.n, parents),  leg.pdg, leg.state))
        singular_structure.legs = sub.SubtractionLegSet(new_subtraction_legs)
        for ss in singular_structure.substructures:
            self.map_leg_numbers_in_singular_structure(leg_numbers_map,ss,parents)

    @classmethod
    def get_parent(cls, children_set, momenta_dict):
        """ retrieves parent index according to the momenta_dict supplied given set of children.
        Returns None if it has no parent. This is very similar to the functiong get_ancestor of the
        Counterm class, except that this function follows relabelling rules if present."""

        if momenta_dict is None:
            return None

        if len(children_set)==1:
            if children_set in momenta_dict.inv:
                # Follow relabelling rule(s)
                return cls.get_parent(frozenset([ momenta_dict.inv[children_set], ]),momenta_dict)
            else:
                return list(children_set)[0]

        if children_set in momenta_dict.inv:
            # Follow relabelling rule(s)
            return cls.get_parent(frozenset([ momenta_dict.inv[children_set], ]), momenta_dict)

        new_children_set = frozenset(children_set)
        for key in momenta_dict.inv.keys():
            if len(key)==1 or key.isdisjoint(new_children_set):
                continue
            if key.issubset(new_children_set):
                new_children_set = new_children_set.difference(key)
                new_children_set = new_children_set.union(frozenset([ momenta_dict.inv[key], ]))
        if new_children_set!=children_set:
            return cls.get_parent(new_children_set, momenta_dict)
        else:
            raise CurrentImplementationError("Could not determine the parents of children %s"%str(children_set)+
                                             " from the momenta_dict supplied: %s"%str(momenta_dict))


    @classmethod
    def has_parent(cls, singular_structure_bundle, n_children):
        """ Tests whether the singular structure of a bundle has a parent and raises an error if it
        should have more than one. """

        n_parents = n_children - singular_structure_bundle.count_unresolved()
        if n_parents==0:
            return False
        elif n_parents==1:
            return True
        else:
            raise CurrentImplementationError("A bundle singular structure should have one or zero parents, but"+
                                             " %s has %d."%(str(singular_structure_bundle), n_parents))

    def evaluate_subtraction_current( self,
        current, higher_PS_point=None, momenta_dict=None, reduced_process=None,
        hel_config=None, mu_r = None, mu_fs=(None,None), xis=(None,None), Q=None,
        track_leg_numbers = True, allowed_backward_evolved_flavors=('ALL','ALL'), **opts ):

        if higher_PS_point is None:
            raise CurrentImplementationError(
                self.name() + " needs the higher phase-space point.")
        if xis is None or len(xis)<2:
            raise CurrentImplementationError(
                self.name() + " requires xi's convolutional values to be specfied.")
        if mu_r is None or mu_fs is None:
            raise CurrentImplementationError(
                self.name() + " requires all scales mu_r, mu_f1, muf2 to be specified.")
        if reduced_process is None:
            raise CurrentImplementationError(
                self.name() + " requires a reduced_process.")
        if (hel_config is not None) and not self.supports_helicity_assignment:
            raise CurrentImplementationError(
                self.name() + " does not support helicity assignment.")
        if Q is None:
            raise CurrentImplementationError(
                self.name() + " requires specification of the total incoming momentum Q.")

        # Retrieve alpha_s and mu_r
        model_param_dict = self.model.get('parameter_dict')
        alpha_s = model_param_dict['aS']

        # Make sure it was correctly updated, otherwise directly take the value from mu_r in argument
        mu_r = model_param_dict['MU_R']

        # The determining leg_numbers_map for the application of the mapping rules is by design the one of the
        # *first* defining current
        leg_numbers_map = self.currents_properties[0]['leg_numbers_map']

        # For squared orders we consider the aggregate of squared orders in all currents
        squared_orders = {}
        for crt_properties in self.currents_properties:
            for order, value in crt_properties['squared_orders'].items():
                if order in squared_orders:
                    squared_orders[order] += value
                else:
                    squared_orders[order] = value

        # Similarly the structure considered for applying the mapping rule is once again the one of the
        # first defining current (so self.defining_currents[0])
        # Using then the first current in the first list of defining currents (so self.defining_currents[0][0])
        # is fine for the purpose below since they should all use the same leg numbers
        # The top-level substructures should then be the independent bundles
        # eg (C(1,2),C(4,5),S(6)).
        defining_structure = self.defining_currents[0][0].get('singular_structure').unpack()

        # Make sure a lower_PS_point is generated even if no mapping rule was necessary (as it is for instance the case
        # for integrated counterterms).
        all_steps = [{'higher_PS_point': higher_PS_point},]
        overall_jacobian = 1.

        # Retrieve leg numbers
        overall_children = [] # the legs becoming unresolved in the resolved process (momenta in the real-emission ME)
        overall_parents = [] # the parent legs in the top-level reduced process (momenta in the mapped ME of this CT)

        if len(self.mapping_rules) == 0:
            # When no mapping is necessary, we must still define a default lower_PS_point for the first step that is
            # identical to the higher PS point.
            all_steps[0]['lower_PS_point'] = all_steps[0]['higher_PS_point']

        for bundle in defining_structure.substructures:
            overall_children.append(tuple(leg_numbers_map[l.n] for l in bundle.get_all_legs()))
            if self.has_parent(bundle, len(overall_children[-1])):
                overall_parents.append(self.get_parent(frozenset(overall_children[-1]), momenta_dict))
            else:
                overall_parents.append(None)

        for i_step, mapping_information in enumerate(self.mapping_rules):
            # Now obtain recoilers
            reduced_recoilers = mapping_information['reduced_recoilers'](reduced_process, excluded=tuple(overall_parents))
            additional_recoilers = sub.SubtractionLegSet( SubtractionLeg(
                        self.map_leg_number(leg_numbers_map, l.n, overall_parents),l.pdg,l.state)
                                                                    for l in mapping_information['additional_recoilers'] )
            all_recoilers = sub.SubtractionLegSet( list(reduced_recoilers)+list(additional_recoilers))

            # Now recursively apply leg numbers mappings
            mapping_singular_structure = mapping_information['singular_structure'].get_copy()
            self.map_leg_numbers_in_singular_structure(leg_numbers_map, mapping_singular_structure, overall_parents)
            # Now assign the recoilers (whose leg numbers have already been mapped)
            mapping_singular_structure.legs = all_recoilers

            # Build the momenta_dict by also substituting leg numbers
            this_momenta_dict = bidict({self.map_leg_number(leg_numbers_map, k,overall_parents):frozenset([
                self.map_leg_number(leg_numbers_map, n, overall_parents) for n in v]) for k,v in mapping_information['momenta_dict'].items()})

            lower_PS_point, mapping_vars = mapping_information['mapping'].map_to_lower_multiplicity(
                all_steps[-1]['higher_PS_point'], mapping_singular_structure, this_momenta_dict,
                compute_jacobian=self.divide_by_jacobian)
            if mappings.RelabellingMapping.needs_relabelling(this_momenta_dict):
                lower_PS_point = mappings.RelabellingMapping.map_to_lower_multiplicity(lower_PS_point, None, this_momenta_dict)

            all_steps[-1]['lower_PS_point'] = lower_PS_point
            # Q is provided externally
            mapping_vars.pop('Q', None)
            all_steps[-1]['mapping_vars'] = mapping_vars

            overall_jacobian *= mapping_vars.get('jacobian', 1.)

            bundles_info = []
            for bundle in mapping_singular_structure.substructures:
                bundles_info.append({})
                all_legs = bundle.get_all_legs()
                # This sorting is important so that the variables generated can be related to the legs specified
                # in the mapping singular structures of the mapping rules
                all_initial_legs = sorted([l for l in all_legs if l.state==l.INITIAL], key = lambda l: l.n)
                all_final_legs = sorted([l for l in all_legs if l.state==l.FINAL], key = lambda l: l.n)
                bundles_info[-1]['initial_state_children'] = tuple(l.n for l in all_initial_legs)
                bundles_info[-1]['final_state_children'] = tuple(l.n for l in all_final_legs)
                if self.has_parent(bundle, len(all_legs)):
                    bundles_info[-1]['parent'] = self.get_parent(frozenset(l.n for l in all_legs),this_momenta_dict)
                else:
                    bundles_info[-1]['parent'] = None

                # Retrieve kinematics
                bundles_info[-1]['cut_inputs'] = {}
                if bundle.name() == 'C':
                    if len(all_initial_legs)>0:
                        bundles_info[-1]['cut_inputs']['pA'] = -sum(all_steps[-1]['higher_PS_point'][l.n] for l in all_initial_legs)
                    bundles_info[-1]['cut_inputs']['pC'] = sum(all_steps[-1]['higher_PS_point'][l.n] for l in all_final_legs)
                elif bundle.name() == 'S':
                    bundles_info[-1]['cut_inputs']['pS'] = sum(all_steps[-1]['higher_PS_point'][l.n] for l in all_final_legs)

            all_steps[-1]['bundles_info'] = bundles_info

            # Get all variables for this level
            if mapping_information['variables'] is not None:
                all_steps[-1]['variables'] = mapping_information['variables'](
                    all_steps[-1]['higher_PS_point'], all_steps[-1]['lower_PS_point'],
                    bundles_info, Q=Q, **mapping_vars)
            else:
                all_steps[-1]['variables'] = {}

            # Add the next higher PS point for the next level if necessary
            if i_step<(len(self.mapping_rules)-1):
                all_steps.append({'higher_PS_point':lower_PS_point})

        overall_lower_PS_point = all_steps[-1]['lower_PS_point']

        global_variables = {
                'overall_children': overall_children,
                'overall_parents' : overall_parents,
                'leg_numbers_map' : leg_numbers_map,
                'Q' : Q,
                'mu_r': mu_r,
                'allowed_backward_evolved_flavors': allowed_backward_evolved_flavors,
                'xis' : xis,
                'mu_fs' : mu_fs
        }
        # Build global variables if necessary
        if self.variables is not None:
            global_variables.update(self.variables(reduced_process, all_steps, global_variables))

        # Apply cuts: include the counterterm only in a part of the phase-space
        for i_step, mapping_rule in enumerate(self.mapping_rules):
            cut_inputs = dict(all_steps[i_step])
            if mapping_rule['is_cut'](cut_inputs, global_variables):
                return utils.SubtractionCurrentResult.zero(
                    current=current, hel_config=hel_config,
                    reduced_kinematics=('IS_CUT', (overall_lower_PS_point, xis[:2]) ))

#        for i_step, step_info in enumerate(all_steps):
#            misc.sprint("Higher PS point at step #%d: %s"%(i_step, str(step_info['higher_PS_point'])))
#            misc.sprint("Lower PS point at step  #%d: %s"%(i_step, str(step_info['lower_PS_point'])))

        # Evaluate kernel
        evaluation = self.subtraction_current_evaluation_class({
            'spin_correlations' : [ None, ],
            'color_correlations': [ None, ],
            'Bjorken_rescalings': [ (xis[0], xis[1]), ],
            'reduced_kinematics': [ (None, overall_lower_PS_point), ],
            'values': { }
        })

        # Apply collinear kernel (can be dummy)
        evaluation = self.kernel(evaluation, all_steps, global_variables)

        # Apply soft kernel (can be dummy), which also knows about the reduced process
        evaluation = self.call_soft_kernel(evaluation, reduced_process, all_steps, global_variables)

        # Add the normalization factors
        # WARNING! In this implementation the propagator denominators must be included in the kernel evaluation.
        norm = (8. * math.pi * alpha_s) ** (squared_orders['QCD']/2)
        norm /= overall_jacobian
        for k in evaluation['values']:
            for term in evaluation['values'][k]:
                if isinstance(evaluation['values'][k][term], dict):
                    for key in evaluation['values'][k][term]:
                        evaluation['values'][k][term][key] *= norm
                else:
                    evaluation['values'][k][term] *= norm

        # Construct and return result
        result = utils.SubtractionCurrentResult()
        result.add_result(
            evaluation,
            hel_config=hel_config,
            squared_orders=tuple(sorted(squared_orders.items())))

        return result